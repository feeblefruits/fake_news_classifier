{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "import string\n",
    "import re\n",
    "import bs4 as BeautifulSoup\n",
    "import fasttext\n",
    "\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fakenews_corpus_2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 130444 entries, 0 to 130443\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  130444 non-null  int64 \n",
      " 1   title       130443 non-null  object\n",
      " 2   label       130444 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Surprise: Socialist Hotbed Of Venezuela Has Lo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Water Cooler 1/25/18 Open Thread; Fake News ? ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Veteran Commentator Calls Out the Growing “Eth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Lost Words, Hidden Words, Otters, Banks and Books</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Red Alert: Bond Yields Are SCREAMING “Inflatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  label\n",
       "0           0  Surprise: Socialist Hotbed Of Venezuela Has Lo...      0\n",
       "1           1  Water Cooler 1/25/18 Open Thread; Fake News ? ...      0\n",
       "2           2  Veteran Commentator Calls Out the Growing “Eth...      0\n",
       "3           3  Lost Words, Hidden Words, Otters, Banks and Books      0\n",
       "4           4  Red Alert: Bond Yields Are SCREAMING “Inflatio...      0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    123849\n",
       "1      6594\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Define pipeline settings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of simplicity and just being neat a seperate library is imported, holding the custom transformers\n",
    "\n",
    "from custom_transformers import CharCounter\n",
    "from custom_transformers import CaseCounter\n",
    "from custom_transformers import StopWordCounter\n",
    "from custom_transformers import WordPronCounter\n",
    "from custom_transformers import WordNounCounter\n",
    "from custom_transformers import WordAdjCounter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "\n",
    "    '''\n",
    "    INPUT: String to tokenise, detect and replace URLs\n",
    "    OUTPUT: List of tokenised string items\n",
    "    '''\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    # Single character removal\n",
    "    text = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', text)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    text = [w for w in text.split() if not w in stop_words]\n",
    "\n",
    "    # Join list to string\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Replace URLs if any\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    # Setup tokens and lemmatize\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Create tokens and lemmatize\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline():\n",
    "    \n",
    "    '''\n",
    "    INPUT: None\n",
    "    OUTPUT: pipeline object used to .fit X_train and y_train datasets\n",
    "    '''\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ])),\n",
    "            ('char_counter', CharCounter()),\n",
    "            ('case_counter', CaseCounter()),\n",
    "            ('stop_counter', StopWordCounter()),\n",
    "            ('pro_counter', WordPronCounter()),\n",
    "            ('noun_counter', WordNounCounter()),\n",
    "            ('adj_counter', WordAdjCounter())\n",
    "        ])),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['title']\n",
    "Y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacques/opt/anaconda3/envs/data-sci/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = model_pipeline()\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Accuracy results</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(y_test, y_pred):\n",
    "    \n",
    "    '''\n",
    "    INPUT: y_test, y_pred dfs\n",
    "    OUTPUT: print average accuracy score\n",
    "    '''\n",
    "    \n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9741804912452854\n"
     ]
    }
   ],
   "source": [
    "display_results(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more granular performance evaluation, a classification report is initialised and displayed as a pd table\n",
    "\n",
    "report = classification_report(y_true=y_test,\n",
    "                               y_pred=y_pred,\n",
    "                               target_names=['fake','true'],\n",
    "                               output_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow0_col0 {\n",
       "            background-color:  lightgreen;\n",
       "            : ;\n",
       "        }    #T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow0_col1 {\n",
       "            background-color:  lightgreen;\n",
       "            : ;\n",
       "        }    #T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow0_col2 {\n",
       "            background-color:  lightgreen;\n",
       "            : ;\n",
       "        }    #T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow1_col0 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow1_col1 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }    #T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow1_col2 {\n",
       "            : ;\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcb\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >precision</th>        <th class=\"col_heading level0 col1\" >recall</th>        <th class=\"col_heading level0 col2\" >f1-score</th>        <th class=\"col_heading level0 col3\" >support</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcblevel0_row0\" class=\"row_heading level0 row0\" >fake</th>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow0_col0\" class=\"data row0 col0\" >0.975110</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow0_col1\" class=\"data row0 col1\" >0.998323</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow0_col2\" class=\"data row0 col2\" >0.986580</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow0_col3\" class=\"data row0 col3\" >31002.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcblevel0_row1\" class=\"row_heading level0 row1\" >true</th>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow1_col0\" class=\"data row1 col0\" >0.940299</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow1_col1\" class=\"data row1 col1\" >0.509012</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow1_col2\" class=\"data row1 col2\" >0.660484</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow1_col3\" class=\"data row1 col3\" >1609.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcblevel0_row2\" class=\"row_heading level0 row2\" >accuracy</th>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow2_col0\" class=\"data row2 col0\" >0.974180</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow2_col1\" class=\"data row2 col1\" >0.974180</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow2_col2\" class=\"data row2 col2\" >0.974180</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow2_col3\" class=\"data row2 col3\" >0.974180</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcblevel0_row3\" class=\"row_heading level0 row3\" >macro avg</th>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow3_col0\" class=\"data row3 col0\" >0.957704</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow3_col1\" class=\"data row3 col1\" >0.753667</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow3_col2\" class=\"data row3 col2\" >0.823532</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow3_col3\" class=\"data row3 col3\" >32611.000000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcblevel0_row4\" class=\"row_heading level0 row4\" >weighted avg</th>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow4_col0\" class=\"data row4 col0\" >0.973393</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow4_col1\" class=\"data row4 col1\" >0.974180</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow4_col2\" class=\"data row4 col2\" >0.970491</td>\n",
       "                        <td id=\"T_ccf03532_0ba6_11eb_a1cc_38f9d3537bcbrow4_col3\" class=\"data row4 col3\" >32611.000000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fa3e41a56d0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(report).transpose().style\\\n",
    ".highlight_max(color='lightgreen', subset=['precision'])\\\n",
    ".highlight_min(color='lightgreen', subset=['precision'] )\\\n",
    ".highlight_max(color='lightgreen', subset=['recall'])\\\n",
    ".highlight_min(color='lightgreen', subset=['recall'] )\\\n",
    ".highlight_max(color='lightgreen', subset=['f1-score'])\\\n",
    ".highlight_min(color='lightgreen', subset=['f1-score'] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
